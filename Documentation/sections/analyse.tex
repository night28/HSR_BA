\section{Analyse}
Nachfolgend werden alle kritischen Elemente der SDA Lösung analysiert. Dazu gehören beispielsweise Dienste, wie die LISP Datenbank, Radius, SGT Access List. und 

Das Ziel ist die komplette Analyse der SDA Lösung und die Identifizierung der kritischen Elemente der Verfügbarkeit (LISP Database, Radius, SGT Access-list etc.) und der Network Services (NTP, DNS, Lizenzen etc.).

\subsection{SDA Architektur und Design}
Unsere Architektur der Lab Umgebung, welche in der Studienarbeit erarbeitet und nun in der Bachelorarbeit noch erweitert wurde, sieht zur Zeit wie folgend aus:

\begin{figure}[H]
	\centering
	\includegraphics[width=1\linewidth]{img/Architecture/LabNetworkArchitecture-25-09}
	\caption{Architektur}
	\label{fig:Architektur}
\end{figure}

Die Analyse wird auf dieser Architektur aufbauen und die von der FUB gegebenen Grössenordnung berücksichtigen.

Nachfolgend werden die aktuell von Cisco empfohlenen Design Entscheidungen, Grössenüberlegungen, sowie die Skalierungen gezeigt. Aktuelle und ausführliche Informationen hierzu, können direkt im SDA Design Guide von Cisco \cite{sda-designguide} eingesehen werden. 

\subsubsection{Entscheidungen}
Die Design Entscheidungen beruhen auf den aktuellen Empfehlungen von Cisco, welche sich laufend Ändern können.

\begin{figure}[H]
	\centering
	\includegraphics[width=1\linewidth]{img/Analyse/SDAswitchingplatformsanddeploymentcapabilities}
	\caption{SDA switching platforms and deployment capabilities \cite{sda-designguide}}
	\label{fig:SDA switching platforms and deployment capabilities}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=1\linewidth]{img/Analyse/SDAroutingandwirelessplatformsanddeploymentcapabilities}
	\caption{SDA routing and wireless platforms and deployment capabilities \cite{sda-designguide}}
	\label{fig:SDA routing and wireless platforms and deployment capabilities}
\end{figure}

\subsubsection{Grössenüberlegungen}
Es ist zusätzlich zu den oben in den Design Entscheidungen empfohlenen Plattformen wichtig, die nachfolgenden getesteten Werte für Cisco Validated Design (CVD) sowie die Versionshinweise zu Hardware und Software für eine Bereitstellung zu berücksichtigen.

Diese Grössenüberlegungen sind besonders für grosse Unternehmen wichtig, da diese zur Zeit nur bis zur eines gewissen Anzahl von Cisco getestet wurden und im schlechtesten Fall nicht höher unterstützt werden.


\begin{figure}[H]
	\centering
	\includegraphics[width=1\linewidth]{img/Analyse/CVD-DNACmanagementofSDA}
	\caption{DNAC management of SDA \cite{sda-designguide} }
	\label{fig:DNAC management of SDA}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=1\linewidth]{img/Analyse/CVD-DNACwithSDAperFabricDomain}
	\caption{DNAC with SDA per each fabric domain \cite{sda-designguide} }
	\label{fig:DNAC with SDA per each fabric domain}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=1\linewidth]{img/Analyse/CVD-SDAvirtualnetworksbyplatformandrole}
	\caption{SDA virtual networks by platform and role \cite{sda-designguide} }
	\label{fig:SDA virtual networks by platform and role}
\end{figure}


\subsubsection{Skalierungen}
Folgende maximalen Skalierungen sollten für grosse Organisationen besonders berücksichtigt werden. Diese Daten sollten bei der Auswahl von Plattformen, die während der Planung für das aktuelle und zukünftige Wachstum des Netzwerks verwendet werden, berücksichtigt werden.

Die DNAC Nummern sind pro Instanz, bei denen es sich um ein DNAC mit einem einzelnen Server oder einem DNA-Cluster mit drei Servern handeln kann. Die maximalen Zahlen sind entweder die absoluten Grenzen der Plattform oder die empfohlenen Höchstgrenzen aktueller Tests einer einzelnen Plattform.

\begin{figure}[H]
	\centering
	\includegraphics[width=1\linewidth]{img/Analyse/MaxScale-DNAC}
	\caption{DNAC Maximum Scale Recommendations \cite{sda-designguide} }
	\label{fig:DNAC Maximum Scale RecommendationsA}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=1\linewidth]{img/Analyse/MaxScale-EdgeNode}
	\caption{Edge Node Maximum Scale Recommendations \cite{sda-designguide} }
	\label{fig:Edge Node Maximum Scale RecommendationsA}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=1\linewidth]{img/Analyse/MaxScale-BorderNode}
	\caption{Border Node Maximum Scale Recommendations \cite{sda-designguide} }
	\label{fig:Border Node Maximum Scale RecommendationsA}
\end{figure}



\subsection{Verfügbarkeit}
Die Verfügbarkeit der nachfolgenden Dienste sind für den Betrieb eines SDA mit dem DNAC wichtig, um die volle Funktion des Netzwerkes bereitzustellen. Darum ist es von Vorteil, wenn die kritischen Server und Dienste redundant ausgelegt sind.

\subsubsection{DNA Center}

\paragraph{Beschreibung}

Das DNA Center übernimmt verschiedene Funktionen im Netzwerk. Es verwaltet die Konfigurationen der Netzwerkgeräte, überwacht diese und stellt die Funktion der Fabrics sicher. 

\paragraph{Impact}

Sollte das DNA Center ausfallen oder nicht erreichbar sein, hat dies keinen direkten Einfluss auf die Funktionalität des Netzwerks. Dies, da alle nötigen Konfigurationen auf den Netzwerkgeräten vorhanden sind. Es ist allerdings nicht mehr möglich, Änderungen am Netzwerk durchzuführen. Es ist beispielsweise nicht mehr möglich, Änderungen an einer Fabric vorzunehmen, Geräte hinzuzufügen oder Access Ports zu konfigurieren. Des Weiteren kann das DNA Center den Betrieb des Netzes nicht mehr monitoren.

\paragraph{Mögliche Ansätze für mehr Krisenresistenz}

Um die negativen Auswirkungen während eines Ausfalls möglichst gering zu halten, können verschiedene Massnahmen getroffen werden. Dies sind:
* DNA Center Betrieb im Cluster
* DNA Center an verschiedenen Standorten

\subsubsection{LISP Map Server / Control Plane Node}

\paragraph{Beschreibung}

Der LISP Map Server auf dem Control Plane Node verwaltet die RLOCs aller Clients in einer Fabric. Die entsprechenden Edge Nodes melden ihr bekannte Clients an den Control Plane Node, welche diese Information in der LISP Database speichert. Benötigt ein Edge Node die RLOC eines Clients, kann er diesen auf der LISP Database abfragen.

\paragraph{Impact}

Fällt der Control Plane Node aus und die LISP Database steht nicht mehr zur Verfügung, ist die Kommuikation im Netzwerk nur noch eingeschränkt möglich. Clients die sich am selben Edge Node befinden, können weiterhin ohne Einschränkung miteinander kommunizieren. Geräte an anderen Edge Nodes sind nur noch möglich, sofern sich diese im Map-Cache des Source Edge Nodes befinden. Dies gilt ebenfalls für Ziele ausserhalb der Fabric, beispielsweise der Internetzugriff.

\paragraph{Mögliche Ansätze für mehr Krisenresistenz}

Es ist möglich mehrer Control Plane Nodes in einer Fabric zu betreiben. Im DNA Center Release 1.2.5 sind dies bis zu sechs Nodes. Damit kann eine sehr hohe Redundanz gewährleistet werden. Solange mindestens eine Control Plane Node pro Fabric funktioniert, hat der Ausfall der restlichen keinen Einfluss auf den Netzwerkbetrieb.

\subsubsection{ISE / Radius}

\paragraph{Beschreibung}

Die ISE, bzw. ein Radius Server übernimmt alle AAA Aufgaben im Netzwerk. Er ist dafür zuständig, dass sich Clients am Netzwerk authentifizieren können, sowie für die Authentifizierung des DNA Centers auf den Geräten.

\paragraph{Impact}

Fällt dieser Service aus, kann das DNA Center keine Änderungen mehr auf den Devices ausführen. Des Weiteren können sich keine neuen Clients am Netzwerk anmelden. Bereits angemeldete Clients können das Netzwerk solange nutzen, wie Ihre Authentifizierung gültig ist.

\paragraph{Mögliche Ansätze für mehr Krisenresistenz}

Der Radius Server oder ISE kann redundant betrieben werden. Es können mehrere Instanzen in einem Cluster betrieben werden. Des Weiteren ist denkbar, in aussenstellen eine Read-Only Kopie des Radius Servers zu betreiben, damit diese autonom funktionieren können, sollte die Verbindung zum Hauptsitz unterbrochen sein.

\subsubsection{Border Node}

\paragraph{Beschreibung}

Der Border Node stellt die Verbindung der Fabric zu externen Netzwerken sicher. Unter anderem stellt der Border Node den Internetzugriff sicher.

\paragraph{Impact}

Fallen alle Border Nodes einer Fabric aus, können die Clients der Fabric nur noch innerhalb dieser Fabric kommunizieren. Es ist nicht mehr möglich, mit Devices in anderen Fabrics oder Devices ausserhalb der Fabrics, bzw. dem Internet zu kommunizieren.

\paragraph{Mögliche Ansätze für mehr Krisenresistenz}

Es können pro Fabric maximal zwei Border Nodes definiert werden. Damit kann eine Redundanz sichergestellt werden, sodass beim Ausfall eines Nodes keine Einschränkungen für die Clients entstehen. 

\subsubsection{DHCP}

\paragraph{Beschreibung}

Der DHCP Service, in der Lab Umgebung ist dies Infoblox, stellt sicher, dass die Clients im Netzwerk die korrekten IP Adressen erhalten.

\paragraph{Impact}

Fällt der DHCP Service aus, erhalten neue Clients keine IP Adressen mehr. Die Netzwerkkommunikation ist für diese daher unmöglich. Bestehende Clients können ihre bereits bezogene IP Adresse weiter verwenden, bis die Lease Time abgelaufen ist. Danach sind auch diese Clients offline

\paragraph{Mögliche Ansätze für mehr Krisenresistenz}

Infoblox kann als High-Availability Cluster mit zwei Nodes betrieben werden. Damit ist die nötige Redundanz gegeben, sodass ein Node ohne Impact ausfallen kann. Mit dem DNA Center können für Aussenstandorte separate DHCP Server konfiguriert werden, sodass diese bei einem Unterbruch zum Hauptsitz autonom funktionieren können.

\subsubsection{NTP}


\subsubsection{DNS}
Der Domain Name Service (DNS) ost eine wesentliche und oft unterschätzte Komponente in einem Netzwerk. Es ist wichtig, dass DNS im Netzwerk korrekt funktioniert und jederzeit zur Verfügung steht.

Es ist also von Vorteil wenn zur Verbeugung eines Ausfalls des DNS, der Server bzw. der Dienst redundant ausgelegt ist.

\subsubsection{Lizenzen}
Die Lizenzen der Geräte können über das DNAC verwaltet werden. Es muss jedoch keine Internetverbindung bestehen, da kein Lizenzenforcement besteht.

\paragraph{Switches}
Die Lizenzen für die einzelnen Switche müssen beim Kauf unbedingt beachtet werden. Jedoch können auf den Switches die Lizenzen auf einer Evaluation Basis manuell nachgerüstet werden (beispielsweise von IP Base auf IP Services).

\subsection{Hardware}
Bei der Hardware ist zu beachten, dass sowohl der Strom, als auch die Netzwerkverbindungen redundant vorhanden sind. Ebenfalls sollte die Hardware bei einem Stromausfall durch eine USV eine gewisse Zeit weiter betrieben werden können.

\paragraph{Wireless Controller}
Die Wireless Controller müssen redundant ausgelegt sein. Es wird in der nachfolgenden Arbeit aber nicht mehr genauer auf Wireless Controller eingegangen, da diese in der Bachelorarbeit nicht integriert werden.

